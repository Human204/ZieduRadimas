{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image, ImageSequence\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, fftshift, ifft2, ifftshift\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, argrelextrema\n",
    "# from skfda import FDataGrid\n",
    "from numpy import unravel_index\n",
    "import statistics\n",
    "import heapq\n",
    "import pandas as pd\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m crop_2\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m crop_3\n\u001b[1;32m---> 39\u001b[0m     \u001b[43mgc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCropping completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_folder = r'../../Results_Validation/Video005'\n",
    "output_dir_1 = os.path.join(input_folder, 'cropped_object_1')\n",
    "output_dir_2 = os.path.join(input_folder, 'cropped_object_2')\n",
    "output_dir_3 = os.path.join(input_folder, 'cropped_object_3')\n",
    "# input_folder+='\\\\uncropped'\n",
    "os.makedirs(output_dir_1, exist_ok=True)\n",
    "os.makedirs(output_dir_2, exist_ok=True)\n",
    "os.makedirs(output_dir_3, exist_ok=True)\n",
    "\n",
    "object_1_center = (212,376)\n",
    "object_2_center = (580,256)\n",
    "object_3_center = (955,403)\n",
    "crop_size = 250\n",
    "half_crop = crop_size // 2\n",
    "\n",
    "\n",
    "for filename in os.listdir(input_folder)[3:]:\n",
    "    # print(filename)\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # print (file_path)\n",
    "\n",
    "    x1, y1 = object_1_center\n",
    "    x2, y2 = object_2_center\n",
    "    x3, y3 = object_3_center\n",
    "\n",
    "    crop_1 = image[y1 - half_crop:y1 + half_crop, x1 - half_crop:x1 + half_crop]\n",
    "    crop_2 = image[y2 - half_crop:y2 + half_crop, x2 - half_crop:x2 + half_crop]\n",
    "    crop_3 = image[y3 - half_crop:y3 + half_crop, x3 - half_crop:x3 + half_crop]\n",
    "\n",
    "    cv2.imwrite(os.path.join(output_dir_1, f'{filename}_object1.png'), crop_1)\n",
    "    cv2.imwrite(os.path.join(output_dir_2, f'{filename}_object2.png'), crop_2)\n",
    "    cv2.imwrite(os.path.join(output_dir_3, f'{filename}_object2.png'), crop_3)\n",
    "    del image\n",
    "    del crop_1\n",
    "    del crop_2\n",
    "    del crop_3\n",
    "    gc.collect()\n",
    "\n",
    "print(\"Cropping completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
